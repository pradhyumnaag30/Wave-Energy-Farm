{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f054e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ff7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Physics Feature Functions\n",
    "\n",
    "def fast_pairwise_features(X, Y, n_wec):\n",
    "    X_i = X[:, :, None]\n",
    "    X_j = X[:, None, :]\n",
    "    Y_i = Y[:, :, None]\n",
    "    Y_j = Y[:, None, :]\n",
    "\n",
    "    dx = X_i - X_j\n",
    "    dy = Y_i - Y_j\n",
    "\n",
    "    dists = np.sqrt(dx * dx + dy * dy)\n",
    "    angles = np.arctan2(dy, dx)\n",
    "\n",
    "    iu = np.triu_indices(n_wec, k=1)\n",
    "\n",
    "    dist_flat = dists[:, iu[0], iu[1]]\n",
    "    angle_flat = angles[:, iu[0], iu[1]]\n",
    "\n",
    "    dist_cols = [f\"dist_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "    angle_cols = [f\"angle_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(dist_flat, columns=dist_cols),\n",
    "        pd.DataFrame(angle_flat, columns=angle_cols)\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_pca_direction(X, Y):\n",
    "    pts = []\n",
    "    for row_x, row_y in zip(X, Y):\n",
    "        pts.append(np.column_stack([row_x, row_y]))\n",
    "    pts = np.vstack(pts)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(pts)\n",
    "\n",
    "    return pca, pca.components_[0]\n",
    "\n",
    "\n",
    "def compute_alignment_features(X, Y, n_wec, wave_dir):\n",
    "    N = X.shape[0]\n",
    "    feats = np.zeros((N, n_wec * (n_wec - 1) // 2))\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(n_wec):\n",
    "        for j in range(i+1, n_wec):\n",
    "            vec_x = X[:, j] - X[:, i]\n",
    "            vec_y = Y[:, j] - Y[:, i]\n",
    "\n",
    "            norm = np.sqrt(vec_x**2 + vec_y**2) + 1e-8\n",
    "            u_x = vec_x / norm\n",
    "            u_y = vec_y / norm\n",
    "\n",
    "            feats[:, idx] = u_x * wave_dir[0] + u_y * wave_dir[1]\n",
    "            idx += 1\n",
    "\n",
    "    cols = [f\"align_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "    return pd.DataFrame(feats, columns=cols)\n",
    "\n",
    "\n",
    "def convex_hull_area(X, Y):\n",
    "    areas = []\n",
    "    for xs, ys in zip(X, Y):\n",
    "        pts = np.column_stack([xs, ys])\n",
    "        try:\n",
    "            hull = ConvexHull(pts)\n",
    "            areas.append(hull.volume)\n",
    "        except:\n",
    "            areas.append(0.0)\n",
    "    return pd.DataFrame({\"convex_hull_area\": areas})\n",
    "\n",
    "\n",
    "def build_physics_features(df_coords, pca_model=None, wave_dir=None):\n",
    "    n_wec = df_coords.shape[1] // 2\n",
    "\n",
    "    X = df_coords[[f\"X{i}\" for i in range(1, n_wec+1)]].values\n",
    "    Y = df_coords[[f\"Y{i}\" for i in range(1, n_wec+1)]].values\n",
    "\n",
    "    # Fit PCA only on training, reuse for test\n",
    "    if pca_model is None:\n",
    "        pca_model, wave_dir = compute_pca_direction(X, Y)\n",
    "\n",
    "    # pairwise\n",
    "    df_dist, df_angle = fast_pairwise_features(X, Y, n_wec)\n",
    "\n",
    "    # spatial stats\n",
    "    df_stats = pd.DataFrame({\n",
    "        \"min_dist\": df_dist.min(axis=1),\n",
    "        \"mean_dist\": df_dist.mean(axis=1),\n",
    "        \"std_dist\": df_dist.std(axis=1),\n",
    "        \"median_dist\": df_dist.median(axis=1)\n",
    "    })\n",
    "\n",
    "    # convex hull area\n",
    "    df_hull = convex_hull_area(X, Y)\n",
    "\n",
    "    # alignment\n",
    "    df_align = compute_alignment_features(X, Y, n_wec, wave_dir)\n",
    "\n",
    "    full = pd.concat([df_dist, df_angle, df_align, df_stats, df_hull], axis=1)\n",
    "\n",
    "    return full, pca_model, wave_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Defining K Fold Validation\n",
    "\n",
    "def run_kfold_cv(df, region_name, k=5):\n",
    "    coord_cols = [c for c in df.columns if c.startswith(\"X\") or c.startswith(\"Y\")]\n",
    "    X_coords = df[coord_cols].values\n",
    "    y = df[\"Total_Power\"].values\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in kf.split(X_coords):\n",
    "\n",
    "        print(f\"\\n================ Fold {fold}/{k} ({region_name}) ================\\n\")\n",
    "\n",
    "        X_train_coords = df.iloc[train_idx][coord_cols]\n",
    "        X_test_coords  = df.iloc[test_idx][coord_cols]\n",
    "        y_train = y[train_idx]\n",
    "        y_test  = y[test_idx]\n",
    "\n",
    "\n",
    "        X_train_phys, pca_model, wave_dir = build_physics_features(X_train_coords)\n",
    "        X_test_phys, _, _ = build_physics_features(\n",
    "            X_test_coords, pca_model=pca_model, wave_dir=wave_dir\n",
    "        )\n",
    "\n",
    "\n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.01,\n",
    "            num_leaves=64,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_phys, y_train)\n",
    "        preds = model.predict(X_test_phys)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "        mae  = mean_absolute_error(y_test, preds)\n",
    "        r2   = r2_score(y_test, preds)\n",
    "        rel_mae = (mae / np.mean(y_test)) * 100\n",
    "\n",
    "        fold_metrics.append([rmse, mae, r2, rel_mae])\n",
    "\n",
    "        print(f\"RMSE = {rmse:.3f}\")\n",
    "        print(f\"MAE = {mae:.3f}\")\n",
    "        print(f\"R² = {r2:.4f}\")\n",
    "        print(f\"Relative MAE = {rel_mae:.2f}%\")\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "    # Aggregate results\n",
    "    fold_metrics = np.array(fold_metrics)\n",
    "    results = pd.DataFrame({\n",
    "        \"Metric\": [\"RMSE\", \"MAE\", \"R²\", \"Relative MAE (%)\"],\n",
    "        \"Mean\": fold_metrics.mean(axis=0),\n",
    "        \"Std\": fold_metrics.std(axis=0)\n",
    "    })\n",
    "\n",
    "    print(f\"\\n============== FINAL {k}-FOLD RESULTS ({region_name}) ==============\\n\")\n",
    "    print(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e83e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Fold 1/5 (Perth_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.316965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824849\n",
      "[LightGBM] [Info] Number of data points in the train set: 28834, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 3938391.702660\n",
      "RMSE       = 20481.045\n",
      "MAE        = 8896.013\n",
      "R²         = 0.9715\n",
      "Relative MAE = 0.23%\n",
      "\n",
      "================ Fold 2/5 (Perth_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 825056\n",
      "[LightGBM] [Info] Number of data points in the train set: 28834, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 3937759.857651\n",
      "RMSE       = 20505.223\n",
      "MAE        = 8792.595\n",
      "R²         = 0.9721\n",
      "Relative MAE = 0.22%\n",
      "\n",
      "================ Fold 3/5 (Perth_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.333861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824697\n",
      "[LightGBM] [Info] Number of data points in the train set: 28834, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 3938575.023210\n",
      "RMSE       = 21212.065\n",
      "MAE        = 8987.084\n",
      "R²         = 0.9704\n",
      "Relative MAE = 0.23%\n",
      "\n",
      "================ Fold 4/5 (Perth_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824367\n",
      "[LightGBM] [Info] Number of data points in the train set: 28835, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 3938357.743073\n",
      "RMSE       = 21433.815\n",
      "MAE        = 9120.975\n",
      "R²         = 0.9698\n",
      "Relative MAE = 0.23%\n",
      "\n",
      "================ Fold 5/5 (Perth_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 826967\n",
      "[LightGBM] [Info] Number of data points in the train set: 28835, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 3938147.945145\n",
      "RMSE       = 20857.674\n",
      "MAE        = 8881.235\n",
      "R²         = 0.9709\n",
      "Relative MAE = 0.23%\n",
      "\n",
      "============== FINAL 5-FOLD RESULTS (Perth_49) ==============\n",
      "\n",
      "             Metric          Mean         Std\n",
      "0              RMSE  20897.964263  378.282057\n",
      "1               MAE   8935.580250  111.344084\n",
      "2                R²      0.970946    0.000793\n",
      "3  Relative MAE (%)      0.226893    0.002872\n",
      "\n",
      "================ Fold 1/5 (Sydney_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.256295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764623\n",
      "[LightGBM] [Info] Number of data points in the train set: 14371, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 4026542.964234\n",
      "RMSE       = 3917.878\n",
      "MAE        = 1681.264\n",
      "R²         = 0.9970\n",
      "Relative MAE = 0.04%\n",
      "\n",
      "================ Fold 2/5 (Sydney_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.250506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759521\n",
      "[LightGBM] [Info] Number of data points in the train set: 14371, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 4027180.279539\n",
      "RMSE       = 4300.188\n",
      "MAE        = 1744.168\n",
      "R²         = 0.9963\n",
      "Relative MAE = 0.04%\n",
      "\n",
      "================ Fold 3/5 (Sydney_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 759898\n",
      "[LightGBM] [Info] Number of data points in the train set: 14371, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 4026321.921404\n",
      "RMSE       = 4045.504\n",
      "MAE        = 1702.678\n",
      "R²         = 0.9966\n",
      "Relative MAE = 0.04%\n",
      "\n",
      "================ Fold 4/5 (Sydney_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.260437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761412\n",
      "[LightGBM] [Info] Number of data points in the train set: 14371, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 4026557.090008\n",
      "RMSE       = 4561.039\n",
      "MAE        = 1793.267\n",
      "R²         = 0.9958\n",
      "Relative MAE = 0.04%\n",
      "\n",
      "================ Fold 5/5 (Sydney_49) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.277156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 758703\n",
      "[LightGBM] [Info] Number of data points in the train set: 14372, number of used features: 3533\n",
      "[LightGBM] [Info] Start training from score 4026440.040687\n",
      "RMSE       = 4158.994\n",
      "MAE        = 1714.157\n",
      "R²         = 0.9965\n",
      "Relative MAE = 0.04%\n",
      "\n",
      "============== FINAL 5-FOLD RESULTS (Sydney_49) ==============\n",
      "\n",
      "             Metric         Mean         Std\n",
      "0              RMSE  4196.720494  221.574782\n",
      "1               MAE  1727.106789   38.818266\n",
      "2                R²     0.996463    0.000393\n",
      "3  Relative MAE (%)     0.042892    0.000968\n"
     ]
    }
   ],
   "source": [
    "# 3 Run Model\n",
    "\n",
    "df_perth = pd.read_csv(\"Dataset/WEC_Perth_49.csv\")\n",
    "df_sydney = pd.read_csv(\"Dataset/WEC_Sydney_49.csv\")\n",
    "\n",
    "results_perth = run_kfold_cv(df_perth, \"Perth_49\", k=5)\n",
    "results_sydney = run_kfold_cv(df_sydney, \"Sydney_49\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
