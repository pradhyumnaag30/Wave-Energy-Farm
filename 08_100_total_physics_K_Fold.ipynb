{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bd8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8295d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Physics Feature Functions\n",
    "\n",
    "def fast_pairwise_features(X, Y, n_wec):\n",
    "    X_i = X[:, :, None]\n",
    "    X_j = X[:, None, :]\n",
    "    Y_i = Y[:, :, None]\n",
    "    Y_j = Y[:, None, :]\n",
    "\n",
    "    dx = X_i - X_j\n",
    "    dy = Y_i - Y_j\n",
    "\n",
    "    dists = np.sqrt(dx * dx + dy * dy)\n",
    "    angles = np.arctan2(dy, dx)\n",
    "\n",
    "    iu = np.triu_indices(n_wec, k=1)\n",
    "\n",
    "    dist_flat = dists[:, iu[0], iu[1]]\n",
    "    angle_flat = angles[:, iu[0], iu[1]]\n",
    "\n",
    "    dist_cols = [f\"dist_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "    angle_cols = [f\"angle_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame(dist_flat, columns=dist_cols),\n",
    "        pd.DataFrame(angle_flat, columns=angle_cols)\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_pca_direction(X, Y):\n",
    "    pts = []\n",
    "    for row_x, row_y in zip(X, Y):\n",
    "        pts.append(np.column_stack([row_x, row_y]))\n",
    "    pts = np.vstack(pts)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(pts)\n",
    "\n",
    "    return pca, pca.components_[0]\n",
    "\n",
    "\n",
    "def compute_alignment_features(X, Y, n_wec, wave_dir):\n",
    "    N = X.shape[0]\n",
    "    feats = np.zeros((N, n_wec * (n_wec - 1) // 2))\n",
    "\n",
    "    idx = 0\n",
    "    for i in range(n_wec):\n",
    "        for j in range(i+1, n_wec):\n",
    "            vec_x = X[:, j] - X[:, i]\n",
    "            vec_y = Y[:, j] - Y[:, i]\n",
    "\n",
    "            norm = np.sqrt(vec_x**2 + vec_y**2) + 1e-8\n",
    "            u_x = vec_x / norm\n",
    "            u_y = vec_y / norm\n",
    "\n",
    "            feats[:, idx] = u_x * wave_dir[0] + u_y * wave_dir[1]\n",
    "            idx += 1\n",
    "\n",
    "    cols = [f\"align_{i}_{j}\" for i in range(1, n_wec+1) for j in range(i+1, n_wec+1)]\n",
    "    return pd.DataFrame(feats, columns=cols)\n",
    "\n",
    "\n",
    "def convex_hull_area(X, Y):\n",
    "    areas = []\n",
    "    for xs, ys in zip(X, Y):\n",
    "        pts = np.column_stack([xs, ys])\n",
    "        try:\n",
    "            hull = ConvexHull(pts)\n",
    "            areas.append(hull.volume)\n",
    "        except:\n",
    "            areas.append(0.0)\n",
    "    return pd.DataFrame({\"convex_hull_area\": areas})\n",
    "\n",
    "\n",
    "def build_physics_features(df_coords, pca_model=None, wave_dir=None):\n",
    "    n_wec = df_coords.shape[1] // 2\n",
    "\n",
    "    X = df_coords[[f\"X{i}\" for i in range(1, n_wec+1)]].values\n",
    "    Y = df_coords[[f\"Y{i}\" for i in range(1, n_wec+1)]].values\n",
    "\n",
    "    # Fit PCA only on training, reuse for test\n",
    "    if pca_model is None:\n",
    "        pca_model, wave_dir = compute_pca_direction(X, Y)\n",
    "\n",
    "    # pairwise\n",
    "    df_dist, df_angle = fast_pairwise_features(X, Y, n_wec)\n",
    "\n",
    "    # spatial stats\n",
    "    df_stats = pd.DataFrame({\n",
    "        \"min_dist\": df_dist.min(axis=1),\n",
    "        \"mean_dist\": df_dist.mean(axis=1),\n",
    "        \"std_dist\": df_dist.std(axis=1),\n",
    "        \"median_dist\": df_dist.median(axis=1)\n",
    "    })\n",
    "\n",
    "    # convex hull area\n",
    "    df_hull = convex_hull_area(X, Y)\n",
    "\n",
    "    # alignment\n",
    "    df_align = compute_alignment_features(X, Y, n_wec, wave_dir)\n",
    "\n",
    "    full = pd.concat([df_dist, df_angle, df_align, df_stats, df_hull], axis=1)\n",
    "\n",
    "    return full, pca_model, wave_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a66cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Defining K Fold Validation\n",
    "\n",
    "def run_kfold_cv(df, region_name, k=5):\n",
    "    coord_cols = [c for c in df.columns if c.startswith(\"X\") or c.startswith(\"Y\")]\n",
    "    X_coords = df[coord_cols].values\n",
    "    y = df[\"Total_Power\"].values\n",
    "\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_metrics = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in kf.split(X_coords):\n",
    "\n",
    "        print(f\"\\n================ Fold {fold}/{k} ({region_name}) ================\\n\")\n",
    "\n",
    "        X_train_coords = df.iloc[train_idx][coord_cols]\n",
    "        X_test_coords  = df.iloc[test_idx][coord_cols]\n",
    "        y_train = y[train_idx]\n",
    "        y_test  = y[test_idx]\n",
    "\n",
    "\n",
    "        X_train_phys, pca_model, wave_dir = build_physics_features(X_train_coords)\n",
    "        X_test_phys, _, _ = build_physics_features(\n",
    "            X_test_coords, pca_model=pca_model, wave_dir=wave_dir\n",
    "        )\n",
    "\n",
    "\n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.01,\n",
    "            num_leaves=64,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_phys, y_train)\n",
    "        preds = model.predict(X_test_phys)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "        mae  = mean_absolute_error(y_test, preds)\n",
    "        r2   = r2_score(y_test, preds)\n",
    "        rel_mae = (mae / np.mean(y_test)) * 100\n",
    "\n",
    "        fold_metrics.append([rmse, mae, r2, rel_mae])\n",
    "\n",
    "        print(f\"RMSE = {rmse:.3f}\")\n",
    "        print(f\"MAE = {mae:.3f}\")\n",
    "        print(f\"R² = {r2:.4f}\")\n",
    "        print(f\"Relative MAE = {rel_mae:.2f}%\")\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "    # Aggregate results\n",
    "    fold_metrics = np.array(fold_metrics)\n",
    "    results = pd.DataFrame({\n",
    "        \"Metric\": [\"RMSE\", \"MAE\", \"R²\", \"Relative MAE (%)\"],\n",
    "        \"Mean\": fold_metrics.mean(axis=0),\n",
    "        \"Std\": fold_metrics.std(axis=0)\n",
    "    })\n",
    "\n",
    "    print(f\"\\n============== FINAL {k}-FOLD RESULTS ({region_name}) ==============\\n\")\n",
    "    print(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1206953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Fold 1/5 (Perth_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.744800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3732780\n",
      "[LightGBM] [Info] Number of data points in the train set: 5821, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7100077.682185\n",
      "RMSE = 37334.643\n",
      "MAE = 13785.679\n",
      "R² = 0.9622\n",
      "Relative MAE = 0.19%\n",
      "\n",
      "================ Fold 2/5 (Perth_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.734293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3732816\n",
      "[LightGBM] [Info] Number of data points in the train set: 5821, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7101293.942622\n",
      "RMSE = 43626.491\n",
      "MAE = 16930.133\n",
      "R² = 0.9526\n",
      "Relative MAE = 0.24%\n",
      "\n",
      "================ Fold 3/5 (Perth_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.982978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3732060\n",
      "[LightGBM] [Info] Number of data points in the train set: 5822, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7100677.033322\n",
      "RMSE = 42420.384\n",
      "MAE = 15580.383\n",
      "R² = 0.9558\n",
      "Relative MAE = 0.22%\n",
      "\n",
      "================ Fold 4/5 (Perth_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3727870\n",
      "[LightGBM] [Info] Number of data points in the train set: 5822, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7101596.946324\n",
      "RMSE = 42999.013\n",
      "MAE = 17278.800\n",
      "R² = 0.9518\n",
      "Relative MAE = 0.24%\n",
      "\n",
      "================ Fold 5/5 (Perth_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.737025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3733264\n",
      "[LightGBM] [Info] Number of data points in the train set: 5822, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7100665.754466\n",
      "RMSE = 45533.191\n",
      "MAE = 16499.857\n",
      "R² = 0.9478\n",
      "Relative MAE = 0.23%\n",
      "\n",
      "============== FINAL 5-FOLD RESULTS (Perth_100) ==============\n",
      "\n",
      "             Metric          Mean          Std\n",
      "0              RMSE  42382.744507  2732.645411\n",
      "1               MAE  16014.970386  1251.279966\n",
      "2                R²      0.954046     0.004788\n",
      "3  Relative MAE (%)      0.225540     0.017681\n",
      "\n",
      "================ Fold 1/5 (Sydney_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2995447\n",
      "[LightGBM] [Info] Number of data points in the train set: 1854, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7166494.074164\n",
      "RMSE = 14230.998\n",
      "MAE = 6177.164\n",
      "R² = 0.9793\n",
      "Relative MAE = 0.09%\n",
      "\n",
      "================ Fold 2/5 (Sydney_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.331201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2985902\n",
      "[LightGBM] [Info] Number of data points in the train set: 1854, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7166312.681499\n",
      "RMSE = 16554.365\n",
      "MAE = 8057.002\n",
      "R² = 0.9738\n",
      "Relative MAE = 0.11%\n",
      "\n",
      "================ Fold 3/5 (Sydney_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.374551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2978107\n",
      "[LightGBM] [Info] Number of data points in the train set: 1854, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7167490.449029\n",
      "RMSE = 22066.818\n",
      "MAE = 9122.820\n",
      "R² = 0.9577\n",
      "Relative MAE = 0.13%\n",
      "\n",
      "================ Fold 4/5 (Sydney_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.377221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2985003\n",
      "[LightGBM] [Info] Number of data points in the train set: 1855, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7167124.664151\n",
      "RMSE = 17345.262\n",
      "MAE = 8086.183\n",
      "R² = 0.9744\n",
      "Relative MAE = 0.11%\n",
      "\n",
      "================ Fold 5/5 (Sydney_100) ================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.343300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2957838\n",
      "[LightGBM] [Info] Number of data points in the train set: 1855, number of used features: 14855\n",
      "[LightGBM] [Info] Start training from score 7168660.725876\n",
      "RMSE = 22980.903\n",
      "MAE = 8876.444\n",
      "R² = 0.9584\n",
      "Relative MAE = 0.12%\n",
      "\n",
      "============== FINAL 5-FOLD RESULTS (Sydney_100) ==============\n",
      "\n",
      "             Metric          Mean          Std\n",
      "0              RMSE  18635.669145  3348.192260\n",
      "1               MAE   8063.922840  1033.620409\n",
      "2                R²      0.968711     0.008925\n",
      "3  Relative MAE (%)      0.112516     0.014454\n"
     ]
    }
   ],
   "source": [
    "# 3 Run Model\n",
    "\n",
    "df_perth = pd.read_csv(\"Dataset/WEC_Perth_100.csv\")\n",
    "df_sydney = pd.read_csv(\"Dataset/WEC_Sydney_100.csv\")\n",
    "\n",
    "results_perth = run_kfold_cv(df_perth, \"Perth_100\", k=5)\n",
    "results_sydney = run_kfold_cv(df_sydney, \"Sydney_100\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
